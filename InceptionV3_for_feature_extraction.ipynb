{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pre-trained Computer Vision Model for Feature Extraction\n",
    "\n",
    "There are multiple powerful models that have been already pre-trained to recognize certain patterns in images and classify images to multiple classes. Keras provides API to use these models. In this noteook I will use Inception V3.\n",
    "It was pretrained for ImageNet classification (classification of images into 1000 different categories). I will not be using the final predictions, instead I will use the output of a hidden layer that is few layers away from the output. \n",
    "\n",
    "If I use the full output tensor (flatten to form a vector) it will be over 131,000 long. Even for my test sets that are around 11,000 dresses at most, the final matrix (combining feature predictions for each test dress) will be huge and won't fit into my computer memoory. I am instead using a smaller portion of the features that still give over 16,000 predicted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages\n",
    "from keras.preprocessing.image import image\n",
    "from keras.applications import inception_v3\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build the model that uses input from Inception V3 model and output from its hidden layer\n",
    "base_model = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('average_pooling2d_9').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load test data sets to predict features for\n",
    "test_data = pd.read_csv('data/test_images.csv', header=0)\n",
    "test_dresses_small = pd.read_csv('data/test_dresses_small.csv', header=0)\n",
    "test_dresses_large = pd.read_csv('data/test_dresses_large.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction for test part of the main dataset\n",
    "predicted1 = []\n",
    "directory = 'data/cropped_images_300x300/'\n",
    "for i in range(len(test_data)):\n",
    "    image_path = directory + test_data.loc[i, 'short_path']\n",
    "    img = image.load_img(image_path, target_size=(299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    pred = model.predict(img)\n",
    "    flat_pred = pred[0][3].flatten()\n",
    "    predicted1.append(flat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each prediction contains 16384 features.\n"
     ]
    }
   ],
   "source": [
    "print('Each prediction contains', len(predicted1[0]), 'features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory and save the predicted features\n",
    "directory = 'data/predictions/'\n",
    "if not os.path.isdir(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "np.save(directory+'test_predictions_inceptionV3.npy', np.asarray(predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict features for small test set\n",
    "predicted_small = []\n",
    "directory = 'data/test_dresses_small_squared/'\n",
    "for i in range(len(test_dresses_small)):\n",
    "    image_path = directory + 'img' + str(i) + '.png'\n",
    "    img = image.load_img(image_path, target_size=(299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    pred = model.predict(img)\n",
    "    flat_pred = pred[0][3].flatten()\n",
    "    predicted_small.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict features for large test set\n",
    "predicted_large = []\n",
    "directory = 'data/test_dresses_large_squared/'\n",
    "for i in range(len(test_dresses_small)):\n",
    "    image_path = directory + 'img' + str(i) + '.png'\n",
    "    img = image.load_img(image_path, target_size=(299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    pred = model.predict(img)\n",
    "    flat_pred = pred[0][3].flatten()\n",
    "    predicted_large.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "directory = 'data/predictions/'\n",
    "\n",
    "np.save(directory+'small_predictions_inceptionV3.npy', np.asarray(predicted_small))\n",
    "np.save(directory+'large_predictions_inceptionV3.npy', np.asarray(predicted_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "directory = 'data/models/'\n",
    "if not os.path.isdir(directory):\n",
    "    os.mkdir(directory)\n",
    "model.save(directory+'InceptionV3.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Feature Extraction Trained on High Resolution Images\n",
    "\n",
    "Training on low resolution images was relatively fast which allows to experiment. As mentioned earlier the task has no numerical metric to compare performances and is based on human perception of final output. Based on my subjective opinion and using BallTree nearest neighbor unsupervised algorithm for predicting 5 most similar looking ones to a given dress, I decided to use a CNN with 3 hidden convolutional layers. \n",
    "\n",
    "Now I will build a similarly structured model and train it on high resolution images. As I am running all notebooks on my local machine, the training might be slow. Therefore I will start by training the model with just one hidden convolutional layer and gradually add two more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant dataframes loaded\n"
     ]
    }
   ],
   "source": [
    "# load train, validation and test sets\n",
    "train_data = pd.read_csv('data/train_images.csv', header=0)\n",
    "validation_data = pd.read_csv('data/validation_images.csv', header=0)\n",
    "test_data = pd.read_csv('data/test_images.csv', header=0)\n",
    "\n",
    "# load two sets of unlabeled data for further model testing\n",
    "test_dresses_small = pd.read_csv('data/test_dresses_small.csv', header=0)\n",
    "test_dresses_large = pd.read_csv('data/test_dresses_large.csv', header=0)\n",
    "\n",
    "notebook_start=timer()\n",
    "\n",
    "print('Relevant dataframes loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40277 validated image filenames.\n",
      "Found 11651 validated image filenames.\n",
      "Found 9486 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create generators for train, validation and test images\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        validation_split=0.2)\n",
    "\n",
    "attr_columns = list(train_data.drop(['url', 'Unnamed: 0', 'short_path', 'low_res_url'], axis=1).columns)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        directory='data/cropped_images_450x300/',\n",
    "        x_col='short_path',\n",
    "        y_col=attr_columns,\n",
    "        target_size=(450,300),\n",
    "        batch_size=32,\n",
    "        class_mode='raw')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        directory='data/cropped_images_450x300/',\n",
    "        x_col='short_path',\n",
    "        y_col=attr_columns,\n",
    "        target_size=(450,300),\n",
    "        batch_size=32,\n",
    "        class_mode='raw')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=validation_data,\n",
    "        directory='data/cropped_images_450x300/',\n",
    "        x_col='short_path',\n",
    "        y_col=attr_columns,\n",
    "        target_size=(450,300),\n",
    "        batch_size=32,\n",
    "        class_mode='raw')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "n_row = 450\n",
    "n_col = 300\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', padding = 'same', input_shape=[n_row,n_col,3]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(38, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 45s 5s/step - loss: 7.0236 - accuracy: 0.8843 - val_loss: 3.3274 - val_accuracy: 0.9235\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 3.4256 - accuracy: 0.9198 - val_loss: 2.2041 - val_accuracy: 0.8961\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 1.5008 - accuracy: 0.9177 - val_loss: 1.5956 - val_accuracy: 0.9365\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.7488 - accuracy: 0.9305 - val_loss: 0.4140 - val_accuracy: 0.9276\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.4342 - accuracy: 0.9354 - val_loss: 0.5144 - val_accuracy: 0.9447\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.2996 - accuracy: 0.9382 - val_loss: 0.4542 - val_accuracy: 0.9439\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.2681 - accuracy: 0.9447 - val_loss: 0.4697 - val_accuracy: 0.9419\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2472 - accuracy: 0.9418 - val_loss: 0.2910 - val_accuracy: 0.9507\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.2210 - accuracy: 0.9456 - val_loss: 0.3471 - val_accuracy: 0.9461\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.2206 - accuracy: 0.9430 - val_loss: 0.3005 - val_accuracy: 0.9479\n",
      "First model trained in  0:06:59.436269\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = timer()\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=10, epochs=10, \n",
    "                     validation_data=validation_generator, validation_steps=5)\n",
    "\n",
    "end = timer()\n",
    "print('First model trained in ',timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model reusing first layers of the previous one and adding extra convolutional layer\n",
    "model2 = Sequential(model.layers[:-2])\n",
    "model2.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model2.add(MaxPooling2D(2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(38, activation='sigmoid'))\n",
    "\n",
    "# freeze layers from the first model\n",
    "for layer in model2.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.1902 - accuracy: 0.9453 - val_loss: 0.1861 - val_accuracy: 0.9456\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1944 - accuracy: 0.9439 - val_loss: 0.1889 - val_accuracy: 0.9456\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1899 - accuracy: 0.9453 - val_loss: 0.2083 - val_accuracy: 0.9419\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1947 - accuracy: 0.9424 - val_loss: 0.1382 - val_accuracy: 0.9462\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1820 - accuracy: 0.9443 - val_loss: 0.1696 - val_accuracy: 0.9464\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1846 - accuracy: 0.9474 - val_loss: 0.1789 - val_accuracy: 0.9462\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1873 - accuracy: 0.9456 - val_loss: 0.2136 - val_accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1838 - accuracy: 0.9451 - val_loss: 0.1831 - val_accuracy: 0.9515\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1815 - accuracy: 0.9457 - val_loss: 0.1966 - val_accuracy: 0.9469\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.1819 - accuracy: 0.9472 - val_loss: 0.1972 - val_accuracy: 0.9479\n",
      "Model#2 trained in  0:05:41.354718\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = timer()\n",
    "history = model2.fit_generator(train_generator, steps_per_epoch=10, epochs=10, \n",
    "                     validation_data=validation_generator, validation_steps=5)\n",
    "\n",
    "end = timer()\n",
    "print('Model#2 trained in ',timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model reusing first layers of the previous one and adding extra convolutional layer \n",
    "# model with three hidden layers\n",
    "model3 = Sequential(model2.layers[:-2])\n",
    "model3.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model3.add(MaxPooling2D(2))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(38, activation='sigmoid'))\n",
    "\n",
    "# freeze layers from the first model\n",
    "for layer in model3.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.3318 - accuracy: 0.9047 - val_loss: 0.2424 - val_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.2409 - accuracy: 0.9447 - val_loss: 0.2211 - val_accuracy: 0.9461\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.2030 - accuracy: 0.9460 - val_loss: 0.2188 - val_accuracy: 0.9431\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.1971 - accuracy: 0.9466 - val_loss: 0.1503 - val_accuracy: 0.9465\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1861 - accuracy: 0.9472 - val_loss: 0.1740 - val_accuracy: 0.9451\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.2016 - accuracy: 0.9427 - val_loss: 0.1975 - val_accuracy: 0.9452\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1955 - accuracy: 0.9439 - val_loss: 0.2151 - val_accuracy: 0.9428\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1952 - accuracy: 0.9432 - val_loss: 0.1927 - val_accuracy: 0.9510\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1906 - accuracy: 0.9447 - val_loss: 0.1977 - val_accuracy: 0.9474\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.1902 - accuracy: 0.9424 - val_loss: 0.1971 - val_accuracy: 0.9482\n",
      "Model#3 trained in  0:05:07.327152\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = timer()\n",
    "history = model3.fit_generator(train_generator, steps_per_epoch=10, epochs=10, \n",
    "                     validation_data=validation_generator, validation_steps=5)\n",
    "\n",
    "end = timer()\n",
    "print('Model#3 trained in ',timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now unfreeze all layers and perform training on the whole model for few epochs to give the CNN the idea of the full picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze layers from the first model\n",
    "for layer in model3.layers[:-4]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 58s 6s/step - loss: 0.1912 - accuracy: 0.9451 - val_loss: 0.1811 - val_accuracy: 0.9462\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 58s 6s/step - loss: 0.1917 - accuracy: 0.9447 - val_loss: 0.1806 - val_accuracy: 0.9464\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.1884 - accuracy: 0.9465 - val_loss: 0.2087 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.1937 - accuracy: 0.9448 - val_loss: 0.1464 - val_accuracy: 0.9467\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.1990 - accuracy: 0.9423 - val_loss: 0.1634 - val_accuracy: 0.9456\n",
      "Model#3 retrained in  0:04:44.317095\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = timer()\n",
    "history = model3.fit_generator(train_generator, steps_per_epoch=10, epochs=5, \n",
    "                     validation_data=validation_generator, validation_steps=5)\n",
    "\n",
    "end = timer()\n",
    "print('Model#3 retrained in ',timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model training, I will use the latest model to make predictions for 3 test sets and save them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict features for test images from labeled dataset\n",
    "test_predictions = model3.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict features for small test set\n",
    "predicted_small = []\n",
    "directory = 'data/test_dresses_small/'\n",
    "for i in range(len(test_dresses_small)):\n",
    "    image_path = directory + 'img' + str(i) + '.png'\n",
    "    img = image.load_img(image_path, target_size=(450,300))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = model3.predict(img)\n",
    "    predicted_small.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict features for large test set\n",
    "predicted_large = []\n",
    "directory = 'data/test_dresses_large/'\n",
    "for i in range(len(test_dresses_large)):\n",
    "    image_path = directory + 'img' + str(i) + '.png'\n",
    "    img = image.load_img(image_path, target_size=(450,300))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = model3.predict(img)\n",
    "    predicted_large.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory\n",
    "directory = 'data/predictions/'\n",
    "if not os.path.isdir(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "np.save(directory+'test_predictions_hr.npy', test_predictions)\n",
    "np.save(directory+'small_predictions_hr.npy', np.asarray(predicted_small))\n",
    "np.save(directory+'large_predictions_hr.npy', np.asarray(predicted_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "directory = 'data/models/'\n",
    "if not os.path.isdir(directory):\n",
    "    os.mkdir(directory)\n",
    "model3.save(directory+'CNN_trained_on_high_res_images.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:38:54.237723\n"
     ]
    }
   ],
   "source": [
    "notebook_end = timer()\n",
    "print(timedelta(seconds=notebook_end-notebook_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
